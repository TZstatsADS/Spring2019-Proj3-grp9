{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super-Resolution Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import math\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and Label Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set train data directories\n",
    "train_LR_dir = \"../data/train_set/LR/\"\n",
    "train_HR_dir = \"../data/train_set/HR/\"\n",
    "LR_dir_name = os.listdir(train_LR_dir)\n",
    "HR_dir_name = os.listdir(train_HR_dir)\n",
    "n_files = len(LR_dir_name)\n",
    "#initial values\n",
    "Random_Crop =30 #number of sample patches\n",
    "Patch_size = 32 \n",
    "label_size = 20\n",
    "conv_side = 6 \n",
    "learn_rate = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_start_time = time.time()\n",
    "#Set feature and label dimension\n",
    "train_data = numpy.zeros((n_files * Random_Crop,  Patch_size, Patch_size,1), dtype=numpy.double) #feature size 32 * 32 * 1\n",
    "train_label = numpy.zeros((n_files * Random_Crop,  label_size, label_size,1), dtype=numpy.double) #label size 20 * 20 * 1\n",
    "\n",
    "for i in range(n_files):\n",
    "    \n",
    "    LR_file_path = train_LR_dir + LR_dir_name[i] #Low Resolution image path\n",
    "    HR_file_path = train_HR_dir + HR_dir_name[i] #High Resolution image path\n",
    "    \n",
    "    hr_img = cv2.imread(HR_file_path,cv2.IMREAD_COLOR) #Read High Resolution image as label\n",
    "    hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb) #Convert RGB to YCrCb Color type\n",
    "    hr_img = hr_img[:, :, 0] #Use Y color channel for trainning\n",
    "    shape = hr_img.shape #High Resolution shape\n",
    "    \n",
    "    lr_img = cv2.imread(LR_file_path,cv2.IMREAD_COLOR)# Read low Resolution image as feature\n",
    "    lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2YCrCb)#Convert RGB to YCrCb Color type\n",
    "    lr_img = lr_img[:, :, 0]#Use Y color channel for trainning\n",
    "    lr_img = cv2.resize(lr_img,(shape[1],shape[0]),interpolation = cv2.INTER_CUBIC) #Resize the LR to HR size using cubic interpolation\n",
    "    \n",
    "    #Select random points\n",
    "    numpy.random.seed(2019)\n",
    "    Points_x = numpy.random.randint(0, shape[0]- Patch_size, Random_Crop)\n",
    "    Points_y = numpy.random.randint(0, shape[1]- Patch_size, Random_Crop)   \n",
    "    \n",
    "    #Construct patches by random points\n",
    "    for j in range(Random_Crop):\n",
    "        lr_patch = lr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "        hr_patch = hr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "   \n",
    "    #Convert pixel range from (0,255) to (0,1)\n",
    "        lr_patch = lr_patch.astype(float) / 255.\n",
    "        hr_patch = hr_patch.astype(float) / 255.\n",
    "    \n",
    "    #Construct feature and label matrix\n",
    "        train_data[i * Random_Crop + j,  :, :,0] = lr_patch\n",
    "        train_label[i * Random_Crop + j, :, :,0] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "        \n",
    "feature_end_time = time.time()\n",
    "feature_time = feature_end_time - feature_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 32, 32, 1)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 20, 20, 1)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write h5 file for feature and label construction\n",
    "def write_h5py(x,y):\n",
    "    x = train_data.astype(numpy.float32)\n",
    "    y = train_label.astype(numpy.float32)\n",
    "    with h5py.File(\"../lib/train.h5\", 'w') as h:\n",
    "        h.create_dataset('train_data', data=x, shape=x.shape)\n",
    "        h.create_dataset('train_label', data=y, shape=y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save train feature h5py file\n",
    "#write_h5py(train_data,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading saved h5py train feature file\n",
    "def read_training_data(file):\n",
    "    with h5py.File(file, 'r') as hf:\n",
    "        data = numpy.array(hf.get('train_data'))\n",
    "        label = numpy.array(hf.get('train_label'))\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,train_label =  read_training_data(\"../lib/train.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build trainning model\n",
    "def train_model():\n",
    "    SRCNN = tf.keras.Sequential()\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(64, kernel_size=9,activation='relu', padding='valid',input_shape=(Patch_size, Patch_size, 1)))#patch size\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(32, kernel_size=1,activation='relu', padding='valid'))\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(1, kernel_size=5,activation='linear', padding='valid'))\n",
    "    adam = tf.keras.optimizers.Adam(lr=learn_rate)\n",
    "    SRCNN.compile(optimizer=adam, loss='mse')\n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_81 (Conv2D)           (None, 24, 24, 64)        5248      \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 24, 24, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 20, 20, 1)         801       \n",
      "=================================================================\n",
      "Total params: 8,129\n",
      "Trainable params: 8,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "SRCNN_train = train_model()\n",
    "print(SRCNN_train.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 3s 62us/step - loss: 0.0089\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0026\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0026\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0025\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0025\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 2s 49us/step - loss: 0.0025\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 2s 50us/step - loss: 0.0025\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 2s 50us/step - loss: 0.0025\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 2s 50us/step - loss: 0.0025\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0025\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 2s 52us/step - loss: 0.0025\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 2s 52us/step - loss: 0.0024\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 2s 53us/step - loss: 0.0024\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - ETA: 0s - loss: 0.002 - 2s 51us/step - loss: 0.0024\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024: 0s - loss: 0.0\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024: 0s \n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0024\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023: 0s\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 2s 51us/step - loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "train_start_time = time.time()\n",
    "training = SRCNN_train.fit(train_data,train_label,batch_size=128,epochs=100)\n",
    "train_end_time = time.time()\n",
    "train_time = train_end_time - train_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training.history['loss'],color = 'red')\n",
    "plt.title('mean square error over 100 epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data mse: 0.0023110840724160273   psnr : 26.36 \n"
     ]
    }
   ],
   "source": [
    "train_mse = training.history['loss'][-1]\n",
    "train_psnr = round(20 * math.log10(1.) - 10 * math.log10(train_mse),2)\n",
    "print('Training data mse: {}   psnr : {} '.format(train_mse,train_psnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save training model weights\n",
    "SRCNN_train.save_weights(\"../lib/my_weight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buiding predict model\n",
    "def predict_model():\n",
    "    SRCNN = tf.keras.Sequential()\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(64, kernel_size=9,activation='relu', padding='valid',input_shape=(None, None, 1)))\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(32, kernel_size=1,activation='relu', padding='valid'))\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(1, kernel_size=5,activation='linear', padding='valid'))\n",
    "    adam = tf.keras.optimizers.Adam(lr=learn_rate)\n",
    "    SRCNN.compile(optimizer=adam, loss='mse', metrics=['mse'])\n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model and weights\n",
    "SRCNN_pred = predict_model()\n",
    "SRCNN_pred.load_weights(\"../lib/my_weight.h5\")\n",
    "#Set test data directories\n",
    "test_lr_dir = \"../data/test_set/LR/\"\n",
    "test_super_dir = \"../data/test_set/SR-I/\"\n",
    "test_hr_dir = \"../data/test_set/HR/\"\n",
    "test_lr_name = os.listdir(test_lr_dir)\n",
    "n_test_files = len(test_lr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict SR\n",
    "predict_start_time= time.time()\n",
    "\n",
    "for i in range(n_test_files):\n",
    "    test_lr_img_path= test_lr_dir + test_lr_name[i]\n",
    "    test_lr_img = cv2.imread(test_lr_img_path,cv2.IMREAD_COLOR) \n",
    "    test_lr_img = cv2.cvtColor(test_lr_img,cv2.COLOR_BGR2YCrCb) #convert to YCrCb color type  \n",
    "    t_shape = test_lr_img.shape\n",
    "    \n",
    "    #double the size of LR by cubic interpolation\n",
    "    test_lr_img = cv2.resize(test_lr_img,(t_shape[1]*2,t_shape[0]*2),interpolation = cv2.INTER_CUBIC)\n",
    "    new_shape = test_lr_img.shape\n",
    "\n",
    "    #Construct feature dimension for CNN (1*height*width*1)\n",
    "    Y_img = test_lr_img[:,:,0]     \n",
    "    Y = numpy.zeros((1, new_shape[0], new_shape[1], 1), dtype=float)\n",
    "    Y[0, :, :, 0] = Y_img.astype(float) / 255.     \n",
    "    \n",
    "    #predict super resolution images\n",
    "    pre = SRCNN_pred.predict(Y, batch_size=1) * 255.  \n",
    "    pre[pre[:] > 255] = 255\n",
    "    pre[pre[:] < 0] = 0 \n",
    "    pre = pre.astype(numpy.uint8)# integer (0 to 255) type\n",
    "    \n",
    "    #Construct full super resolution images\n",
    "    test_lr_img[6: -6, 6: -6, 0] = pre[0, :, :, 0] \n",
    "    test_lr_img = cv2.cvtColor(test_lr_img,cv2.COLOR_YCrCb2BGR) #convert color back to BGR type\n",
    "    \n",
    "    #Write SR images\n",
    "    cv2.imwrite(os.path.join(test_super_dir, test_lr_name[i]), test_lr_img)\n",
    "    \n",
    "predict_end_time = time.time()\n",
    "predict_time = predict_end_time - predict_start_time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feature and label construction time : {} sec \\n\\nTraining time : {} sec\\n\\nPredicting and writing SR images time : {} sec'.format(feature_time,train_time,predict_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get test image PSNR \n",
    "def get_psnr(HR,SR):\n",
    "    HR = numpy.array(HR,dtype = float)\n",
    "    SR = numpy.array(SR,dtype = float)\n",
    "    DIFF = SR - HR\n",
    "    DIFF = DIFF.flatten('C')    \n",
    "    MSE =numpy.mean(DIFF ** 2.)\n",
    "    PSNR = 20 * math.log10(255.) - 10 * math.log10(MSE)\n",
    "    return PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR = []\n",
    "for i in range(n_test_files):\n",
    "    SR = cv2.imread(os.path.join(test_super_dir,test_lr_name[i]))\n",
    "    HR = cv2.imread(os.path.join(test_hr_dir,test_lr_name[i]))\n",
    "    PSNR.append(get_psnr(HR,SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing data average psnr: {} '.format(numpy.mean(PSNR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "https://github.com/MarkPrecursor/SRCNN-keras\n",
    "\n",
    "https://github.com/tegg89/SRCNN-Tensorflow\n",
    "\n",
    "Dong, C., Loy, C. C., He, K., & Tang, X. (2016). Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine intelligence, 38(2), 295-307.https://arxiv.org/pdf/1501.00092.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
